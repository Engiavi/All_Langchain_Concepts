{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLLM: #dummy LLM Class, that works same as llm\n",
    "    def __init__(self):\n",
    "        print(\"LLM created\")\n",
    "    def predict(self,prompt):\n",
    "        response_list = [\n",
    "            'Delhi is the capital of India',\n",
    "            'IPL is cricket league',\n",
    "            \"AI stands for Artificial Intelligence\",\n",
    "        ]\n",
    "        return {'response':random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    }
   ],
   "source": [
    "llm = BasicLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'AI stands for Artificial Intelligence'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What is the capital of India?\")\n",
    "# it gives random response from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPromptTemplate:\n",
    "    def __init__(self, template,input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "    def Format(self,input_dict):\n",
    "        return self.template.format(**input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template  =BasicPromptTemplate( \n",
    "    template=\"Write a {length} poem about {country}?\",\n",
    "    input_variables=[\"length\",\"country\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.Format({\"country\":\"India\",\"length\":\"short\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'IPL is cricket league'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are building chaining class\n",
    "class BasicLLMChain:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def run(self, input_dict):\n",
    "        prompt = self.prompt.Format(input_dict)\n",
    "        response = self.llm.predict(prompt)\n",
    "        return response['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template  =BasicPromptTemplate( \n",
    "    template=\"Write a {length} poem about {country}?\",\n",
    "    input_variables=[\"length\",\"country\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    }
   ],
   "source": [
    "llm = BasicLLM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = BasicLLMChain(llm=llm, prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IPL is cricket league'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"country\":\"India\",\"length\":\"short\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"the chain was developed to give flexibility to developer, but later langchain messed up with it and made it complex\n",
    "it made complex because of introducing of many chains for each purpose.\n",
    "it becomes difficult to understand and use by newly AI developer.\n",
    "Also if we are use multiple LLMs or Multi-modal, then it becomes more complex when dealing with chains.\n",
    "In day to day life, various project required complex like sequential, parallel, branching, and looping.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" in above code of chainllm, we have a simple case, that is we are going to generate quiz and after that we have generate notes.\n",
    "then we have to call the llm model again and again.\n",
    "hence what functionality can be added in chainllm, to mke it flexible.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" so the solution is 'Runnable'. it basically standardise the above class. \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
